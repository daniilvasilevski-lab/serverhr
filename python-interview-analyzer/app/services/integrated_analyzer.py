"""
–ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∏–Ω—Ç–µ—Ä–≤—å—é
–•–æ–ª–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–¥—Ö–æ–¥ —Å –µ–¥–∏–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–µ–π
"""

import logging
import json
from typing import Dict, List, Any
import asyncio
from datetime import datetime

from ..models.evaluation_criteria import (
    EvaluationCriteria, 
    EvaluationScore, 
    InterviewAnalysis,
    CRITERIA_DESCRIPTIONS
)

logger = logging.getLogger(__name__)


class IntegratedInterviewAnalyzer:
    """
    –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∏–Ω—Ç–µ—Ä–≤—å—é
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤—Å–µ –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–∏ –≤ –µ–¥–∏–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å–µ
    """
    
    def __init__(self, openai_client):
        self.openai_client = openai_client
        
    async def analyze_interview(self, video_url: str, candidate_info: Dict) -> InterviewAnalysis:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∞–Ω–∞–ª–∏–∑–∞ –∏–Ω—Ç–µ—Ä–≤—å—é
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–µ –≤–∏–¥–µ–æ –∏ –∞—É–¥–∏–æ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä—ã
        """
        logger.info(f"Starting integrated analysis for {candidate_info.get('name', 'Unknown')}")
        
        try:
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä—ã
            from .video_processor import create_video_processor
            from .audio_processor import create_audio_processor
            
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä—ã
            video_processor = create_video_processor()
            audio_processor = create_audio_processor()
            
            # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ –∏ –∞—É–¥–∏–æ
            import asyncio
            video_task = asyncio.create_task(video_processor.process_video(video_url))
            audio_task = asyncio.create_task(audio_processor.process_audio(video_url, 'ru'))
            
            # –û–∂–∏–¥–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            video_results, audio_results = await asyncio.gather(video_task, audio_task)
            
            # –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            transcript_data = {
                "transcript": audio_results.get("transcript", ""),
                "linguistic_features": {
                    "vocabulary_richness": audio_results.get("vocabulary_richness", 0.5),
                    "grammar_complexity": audio_results.get("grammar_complexity", 5)
                }
            }
            
            video_data = {
                "duration": video_results.get("duration", 0),
                "emotion_analysis": video_results.get("emotion_analysis", {}),
                "eye_contact_percentage": video_results.get("eye_contact_percentage", 0),
                "posture_confidence": video_results.get("posture_confidence", 5),
                "gesture_frequency": video_results.get("gesture_frequency", 0),
                "video_quality": video_results.get("video_quality", 5)
            }
            
            audio_data = {
                "speech_rate": audio_results.get("speech_rate", 150),
                "speech_clarity": audio_results.get("speech_clarity", 5),
                "average_pitch": audio_results.get("average_pitch", 150.0),
                "pitch_variation": audio_results.get("pitch_variation", 30.0),
                "pause_frequency": audio_results.get("pause_frequency", 5),
                "average_energy": audio_results.get("average_energy", 0.5),
                "audio_quality": audio_results.get("audio_quality", 5)
            }
            
            # –í—ã–∑–æ–≤ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
            return await self.analyze_interview_holistic(
                transcript_data, video_data, audio_data, candidate_info
            )
            
        except Exception as e:
            logger.error(f"Real processing failed, using fallback: {e}")
            # Fallback –∫ –∑–∞–≥–ª—É—à–∫–∞–º –µ—Å–ª–∏ —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫
            return await self._fallback_analysis(video_url, candidate_info)
    
    async def _fallback_analysis(self, video_url: str, candidate_info: Dict) -> InterviewAnalysis:
        """–†–µ–∑–µ—Ä–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å –∑–∞–≥–ª—É—à–∫–∞–º–∏"""
        transcript_data = {
            "transcript": f"–ü—Ä–∏–º–µ—Ä —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞ –¥–ª—è –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ {candidate_info.get('name', 'Unknown')}",
            "linguistic_features": {
                "vocabulary_richness": 0.65,
                "grammar_complexity": 7
            }
        }
        
        video_data = {
            "duration": 300,
            "emotion_analysis": {"happy": 45.0, "neutral": 40.0, "confident": 15.0},
            "eye_contact_percentage": 75.0,
            "posture_confidence": 8,
            "gesture_frequency": 12,
            "video_quality": 8
        }
        
        audio_data = {
            "speech_rate": 145,
            "speech_clarity": 7,
            "average_pitch": 180.5,
            "pitch_variation": 45.2,
            "pause_frequency": 8,
            "average_energy": 0.65,
            "audio_quality": 8
        }
        
        return await self.analyze_interview_holistic(
            transcript_data, video_data, audio_data, candidate_info
        )
        
    async def analyze_interview_holistic(
        self,
        transcript_data: Dict,
        video_data: Dict, 
        audio_data: Dict,
        candidate_info: Dict
    ) -> InterviewAnalysis:
        """
        –•–æ–ª–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∏–Ω—Ç–µ—Ä–≤—å—é —Å —É—á–µ—Ç–æ–º –≤—Å–µ—Ö –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–µ–π
        
        Args:
            transcript_data: –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç –∏ —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑
            video_data: –í–∏–¥–µ–æ-–∞–Ω–∞–ª–∏–∑ (—ç–º–æ—Ü–∏–∏, –∂–µ—Å—Ç—ã, –ø–æ–∑–∞)
            audio_data: –ê—É–¥–∏–æ-–∞–Ω–∞–ª–∏–∑ (—Ç–æ–Ω, —Ç–µ–º–ø, —á–µ—Ç–∫–æ—Å—Ç—å)
            candidate_info: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–∞–Ω–¥–∏–¥–∞—Ç–µ
            
        Returns:
            InterviewAnalysis: –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        """
        candidate_name = candidate_info.get('name', 'Unknown')
        logger.info(f"üî¨ –ù–ê–ß–ê–õ–û –ò–ù–¢–ï–ì–†–ò–†–û–í–ê–ù–ù–û–ì–û –ê–ù–ê–õ–ò–ó–ê –¥–ª—è {candidate_name}")

        # 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ò–ò
        logger.info(f"üìã –≠—Ç–∞–ø 1/4: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–Ω—Ç–µ—Ä–≤—å—é...")
        integrated_context = self._prepare_integrated_context(
            transcript_data, video_data, audio_data, candidate_info
        )
        logger.info(f"   ‚úì –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {integrated_context['interview_content']['duration_seconds']}—Å")
        logger.info(f"   ‚úì –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤: {integrated_context['interview_content']['word_count']}")
        logger.info(f"   ‚úì –î–æ–º–∏–Ω–∏—Ä—É—é—â–∞—è —ç–º–æ—Ü–∏—è: {integrated_context['nonverbal_behavior']['dominant_emotion']}")
        logger.info(f"   ‚úì –ó—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–∞–∫—Ç: {integrated_context['nonverbal_behavior']['eye_contact_percentage']:.1f}%")

        # 2. –ï–¥–∏–Ω—ã–π –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ GPT-4
        logger.info(f"ü§ñ –≠—Ç–∞–ø 2/4: –•–æ–ª–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ GPT-4...")
        comprehensive_analysis = await self._analyze_with_full_context(integrated_context)
        logger.info(f"   ‚úì –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω")

        # 3. –°–æ–∑–¥–∞–Ω–∏–µ –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ—Ü–µ–Ω–æ–∫ —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ –ø—Ä–∏–º–µ—Ä–∞–º–∏
        logger.info(f"üìä –≠—Ç–∞–ø 3/4: –î–µ—Ç–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –ø–æ 10 –∫—Ä–∏—Ç–µ—Ä–∏—è–º...")
        detailed_scores = await self._create_detailed_scores(
            comprehensive_analysis, integrated_context
        )
        logger.info(f"   ‚úì –í—Å–µ 10 –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤ –æ—Ü–µ–Ω–µ–Ω—ã")

        # 4. –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        logger.info(f"üìù –≠—Ç–∞–ø 4/4: –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞...")
        final_analysis = self._build_final_analysis(
            detailed_scores, integrated_context, comprehensive_analysis, candidate_info
        )
        logger.info(f"‚úÖ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù –¥–ª—è {candidate_name}")

        return final_analysis
    
    def _prepare_integrated_context(
        self, 
        transcript_data: Dict,
        video_data: Dict,
        audio_data: Dict,
        candidate_info: Dict
    ) -> Dict:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
        
        return {
            "candidate": {
                "name": candidate_info.get("name", "Unknown"),
                "id": candidate_info.get("id", "unknown"),
                "preferences": candidate_info.get("preferences", "")
            },
            
            "interview_content": {
                "transcript": transcript_data.get("transcript", ""),
                "duration_seconds": video_data.get("duration", 0),
                "word_count": len(transcript_data.get("transcript", "").split()),
                "linguistic_features": transcript_data.get("linguistic_features", {})
            },
            
            "verbal_communication": {
                "speech_rate_wpm": audio_data.get("speech_rate", 150),
                "speech_clarity": audio_data.get("speech_clarity", 5),
                "average_pitch": audio_data.get("average_pitch", 0),
                "pitch_variation": audio_data.get("pitch_variation", 0),
                "pause_frequency": audio_data.get("pause_frequency", 0),
                "energy_level": audio_data.get("average_energy", 0),
                "tempo_classification": self._classify_tempo(audio_data.get("speech_rate", 150))
            },
            
            "nonverbal_behavior": {
                "emotions_distribution": video_data.get("emotion_analysis", {}),
                "dominant_emotion": self._get_dominant_emotion(video_data.get("emotion_analysis", {})),
                "eye_contact_percentage": video_data.get("eye_contact_percentage", 50),
                "posture_confidence": video_data.get("posture_confidence", 5),
                "gesture_frequency": video_data.get("gesture_frequency", 0),
                "gesture_intensity": self._classify_gesture_intensity(video_data.get("gesture_frequency", 0))
            },
            
            "technical_quality": {
                "video_quality": video_data.get("video_quality", 5),
                "audio_quality": audio_data.get("audio_quality", 5),
                "analysis_reliability": self._assess_reliability(video_data, audio_data)
            },
            
            "temporal_synchronization": {
                "speech_emotion_alignment": self._assess_speech_emotion_sync(
                    transcript_data, video_data
                ),
                "gesture_speech_coordination": self._assess_gesture_speech_sync(
                    transcript_data, video_data
                )
            }
        }
    
    async def _analyze_with_full_context(self, context: Dict) -> Dict:
        """
        –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å –ø–æ–ª–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º —á–µ—Ä–µ–∑ GPT-4
        """
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è —Ö–æ–ª–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        analysis_prompt = f"""
–¢—ã —ç–∫—Å–ø–µ—Ä—Ç-–ø—Å–∏—Ö–æ–ª–æ–≥ –∏ HR-—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç, –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π –∏–Ω—Ç–µ—Ä–≤—å—é —Å—Ç—É–¥–µ–Ω—Ç–∞. 
–ü—Ä–æ–≤–µ–¥–∏ –ö–û–ú–ü–õ–ï–ö–°–ù–£–Æ –æ—Ü–µ–Ω–∫—É, —É—á–∏—Ç—ã–≤–∞—è –í–°–ï –∞—Å–ø–µ–∫—Ç—ã –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ.

–ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –ö–ê–ù–î–ò–î–ê–¢–ï:
- –ò–º—è: {context['candidate']['name']}
- –ü—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è: {context['candidate']['preferences']}

–°–û–î–ï–†–ñ–ê–ù–ò–ï –ò–ù–¢–ï–†–í–¨–Æ:
- –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç: "{context['interview_content']['transcript']}"
- –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {context['interview_content']['duration_seconds']} —Å–µ–∫
- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤: {context['interview_content']['word_count']}

–í–ï–†–ë–ê–õ–¨–ù–´–ï –•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö–ò:
- –¢–µ–º–ø —Ä–µ—á–∏: {context['verbal_communication']['speech_rate_wpm']} —Å–ª–æ–≤/–º–∏–Ω ({context['verbal_communication']['tempo_classification']})
- –ß–µ—Ç–∫–æ—Å—Ç—å —Ä–µ—á–∏: {context['verbal_communication']['speech_clarity']}/10
- –°—Ä–µ–¥–Ω—è—è –≤—ã—Å–æ—Ç–∞ —Ç–æ–Ω–∞: {context['verbal_communication']['average_pitch']} –ì—Ü
- –í–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å —Ç–æ–Ω–∞: {context['verbal_communication']['pitch_variation']}
- –ß–∞—Å—Ç–æ—Ç–∞ –ø–∞—É–∑: {context['verbal_communication']['pause_frequency']}
- –£—Ä–æ–≤–µ–Ω—å —ç–Ω–µ—Ä–≥–∏–∏: {context['verbal_communication']['energy_level']:.3f}

–ù–ï–í–ï–†–ë–ê–õ–¨–ù–û–ï –ü–û–í–ï–î–ï–ù–ò–ï:
- –≠–º–æ—Ü–∏–∏: {context['nonverbal_behavior']['emotions_distribution']}
- –î–æ–º–∏–Ω–∏—Ä—É—é—â–∞—è —ç–º–æ—Ü–∏—è: {context['nonverbal_behavior']['dominant_emotion']}
- –ó—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–∞–∫—Ç: {context['nonverbal_behavior']['eye_contact_percentage']:.1f}%
- –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ø–æ–∑—ã: {context['nonverbal_behavior']['posture_confidence']}/10
- –ß–∞—Å—Ç–æ—Ç–∞ –∂–µ—Å—Ç–æ–≤: {context['nonverbal_behavior']['gesture_frequency']} ({context['nonverbal_behavior']['gesture_intensity']})

–°–ò–ù–•–†–û–ù–ò–ó–ê–¶–ò–Ø:
- –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ä–µ—á–∏ –∏ —ç–º–æ—Ü–∏–π: {context['temporal_synchronization']['speech_emotion_alignment']}
- –ö–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—è –∂–µ—Å—Ç–æ–≤ –∏ —Ä–µ—á–∏: {context['temporal_synchronization']['gesture_speech_coordination']}

–ó–ê–î–ê–ß–ê:
–û—Ü–µ–Ω–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –ø–æ 10 –∫—Ä–∏—Ç–µ—Ä–∏—è–º (1-10 –±–∞–ª–ª–æ–≤), —É—á–∏—Ç—ã–≤–∞—è –í–°–ï –¥–∞–Ω–Ω—ã–µ –≤ –∫–æ–º–ø–ª–µ–∫—Å–µ:

1. –ö–æ–º–º—É–Ω–∏–∫–∞—Ç–∏–≤–Ω—ã–µ –Ω–∞–≤—ã–∫–∏ - —è—Å–Ω–æ—Å—Ç—å, —Å—Ç—Ä—É–∫—Ç—É—Ä–∞, –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ
2. –ú–æ—Ç–∏–≤–∞—Ü–∏—è –∫ –æ–±—É—á–µ–Ω–∏—é - —ç–Ω—Ç—É–∑–∏–∞–∑–º, –∂–µ–ª–∞–Ω–∏–µ —Ä–∞–∑–≤–∏–≤–∞—Ç—å—Å—è  
3. –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ –Ω–∞–≤—ã–∫–∏ - –∑–Ω–∞–Ω–∏—è, –æ–ø—ã—Ç, –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏
4. –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–æ–µ –º—ã—à–ª–µ–Ω–∏–µ - –ª–æ–≥–∏–∫–∞, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å
5. –£–º–µ–Ω–∏–µ –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ –º—ã—Å–ª–∏—Ç—å - –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å, –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ—Å—Ç—å –ø–æ–¥—Ö–æ–¥–æ–≤
6. –ö–æ–º–∞–Ω–¥–Ω–∞—è —Ä–∞–±–æ—Ç–∞ - –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫ —Å–æ—Ç—Ä—É–¥–Ω–∏—á–µ—Å—Ç–≤—É
7. –°—Ç—Ä–µ—Å—Å–æ—É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å - —Å–ø–æ–∫–æ–π—Å—Ç–≤–∏–µ, –∫–æ–Ω—Ç—Ä–æ–ª—å —ç–º–æ—Ü–∏–π
8. –ê–¥–∞–ø—Ç–∏–≤–Ω–æ—Å—Ç—å - –≥–∏–±–∫–æ—Å—Ç—å, –æ—Ç–∫—Ä—ã—Ç–æ—Å—Ç—å –∫ –∏–∑–º–µ–Ω–µ–Ω–∏—è–º
9. –ö—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å - –∏–Ω–Ω–æ–≤–∞—Ü–∏–æ–Ω–Ω—ã–µ –∏–¥–µ–∏, —Ç–≤–æ—Ä—á–µ—Å–∫–∏–π –ø–æ–¥—Ö–æ–¥
10. –û–±—â–µ–µ –≤–ø–µ—á–∞—Ç–ª–µ–Ω–∏–µ - –∏—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞

–í–ê–ñ–ù–û: 
- –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –í–ó–ê–ò–ú–û–°–í–Ø–ó–ò –º–µ–∂–¥—É –≤–µ—Ä–±–∞–ª—å–Ω—ã–º –∏ –Ω–µ–≤–µ—Ä–±–∞–ª—å–Ω—ã–º
- –£—á–∏—Ç—ã–≤–∞–π –ö–û–ù–¢–ï–ö–°–¢ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø–∞—É–∑–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ–±–¥—É–º—ã–≤–∞–Ω–∏–µ–º)
- –ò—â–∏ –ü–û–î–¢–í–ï–†–ñ–î–ï–ù–ò–Ø –≤ —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç—è—Ö
- –û—Ç–º–µ—á–∞–π –ü–†–û–¢–ò–í–û–†–ï–ß–ò–Ø –∏ –∏—Ö –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã

–û—Ç–≤–µ—Ç—å –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ:
{{
    "holistic_scores": {{
        "communication_skills": —á–∏—Å–ª–æ,
        "motivation_learning": —á–∏—Å–ª–æ,
        "professional_skills": —á–∏—Å–ª–æ,
        "analytical_thinking": —á–∏—Å–ª–æ,
        "unconventional_thinking": —á–∏—Å–ª–æ,
        "teamwork_ability": —á–∏—Å–ª–æ,
        "stress_resistance": —á–∏—Å–ª–æ,
        "adaptability": —á–∏—Å–ª–æ,
        "creativity_innovation": —á–∏—Å–ª–æ,
        "overall_impression": —á–∏—Å–ª–æ
    }},
    "cross_modal_insights": {{
        "verbal_nonverbal_alignment": "–æ–ø–∏—Å–∞–Ω–∏–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Ä–µ—á–∏ –∏ –ø–æ–≤–µ–¥–µ–Ω–∏—è",
        "emotional_consistency": "–∞–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏",
        "confidence_indicators": "–∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –∏–∑ –≤—Å–µ—Ö –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–µ–π",
        "stress_indicators": "–ø—Ä–∏–∑–Ω–∞–∫–∏ —Å—Ç—Ä–µ—Å—Å–∞ –∏–ª–∏ —Å–ø–æ–∫–æ–π—Å—Ç–≤–∏—è"
    }},
    "detailed_observations": {{
        "communication_skills": ["–∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –ø—Ä–∏–º–µ—Ä 1", "–ø—Ä–∏–º–µ—Ä 2", "–ø—Ä–∏–º–µ—Ä 3"],
        "motivation_learning": ["–ø—Ä–∏–º–µ—Ä 1", "–ø—Ä–∏–º–µ—Ä 2", "–ø—Ä–∏–º–µ—Ä 3"],
        "professional_skills": ["–ø—Ä–∏–º–µ—Ä 1", "–ø—Ä–∏–º–µ—Ä 2", "–ø—Ä–∏–º–µ—Ä 3"],
        "analytical_thinking": ["–ø—Ä–∏–º–µ—Ä 1", "–ø—Ä–∏–º–µ—Ä 2", "–ø—Ä–∏–º–µ—Ä 3"],
        "unconventional_thinking": ["–ø—Ä–∏–º–µ—Ä 1", "–ø—Ä–∏–º–µ—Ä 2", "–ø—Ä–∏–º–µ—Ä 3"],
        "teamwork_ability": ["–ø—Ä–∏–º–µ—Ä 1", "–ø—Ä–∏–º–µ—Ä 2", "–ø—Ä–∏–º–µ—Ä 3"],
        "stress_resistance": ["–ø—Ä–∏–º–µ—Ä 1", "–ø—Ä–∏–º–µ—Ä 2", "–ø—Ä–∏–º–µ—Ä 3"],
        "adaptability": ["–ø—Ä–∏–º–µ—Ä 1", "–ø—Ä–∏–º–µ—Ä 2", "–ø—Ä–∏–º–µ—Ä 3"],
        "creativity_innovation": ["–ø—Ä–∏–º–µ—Ä 1", "–ø—Ä–∏–º–µ—Ä 2", "–ø—Ä–∏–º–µ—Ä 3"],
        "overall_impression": ["–ø—Ä–∏–º–µ—Ä 1", "–ø—Ä–∏–º–µ—Ä 2", "–ø—Ä–∏–º–µ—Ä 3"]
    }},
    "comprehensive_feedback": "–¥–µ—Ç–∞–ª—å–Ω–∞—è –æ–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å —Å —É—á–µ—Ç–æ–º –≤—Å–µ—Ö –∞—Å–ø–µ–∫—Ç–æ–≤",
    "recommendation": "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è —Å –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ–º"
}}
"""

        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {
                        "role": "system", 
                        "content": "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç-–ø—Å–∏—Ö–æ–ª–æ–≥ –∏ HR-—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç —Å 15+ –ª–µ—Ç –æ–ø—ã—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏–Ω—Ç–µ—Ä–≤—å—é. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—à—å —Ü–µ–ª–æ—Å—Ç–Ω–æ, —É—á–∏—Ç—ã–≤–∞—è –≤—Å–µ –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–∏ –≤ –∫–æ–º–ø–ª–µ–∫—Å–µ."
                    },
                    {"role": "user", "content": analysis_prompt}
                ],
                temperature=0.2,  # –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –±–æ–ª–µ–µ –æ–±—ä–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
                max_tokens=4000
            )
            
            content = response.choices[0].message.content
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞
            start_idx = content.find('{')
            end_idx = content.rfind('}') + 1
            
            if start_idx == -1 or end_idx <= start_idx:
                raise ValueError("No valid JSON found in response")
                
            json_str = content[start_idx:end_idx]
            analysis_result = json.loads(json_str)
            
            logger.info("Integrated analysis completed successfully")
            return analysis_result
            
        except Exception as e:
            logger.error(f"Integrated analysis failed: {e}")
            # –í–æ–∑–≤—Ä–∞—Ç –±–∞–∑–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
            return self._get_fallback_analysis()
    
    async def _create_detailed_scores(self, analysis: Dict, context: Dict) -> Dict:
        """–°–æ–∑–¥–∞–Ω–∏–µ –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ—Ü–µ–Ω–æ–∫ —Å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""

        detailed_scores = {}
        scores = analysis.get("holistic_scores", {})
        observations = analysis.get("detailed_observations", {})

        # –ù–∞–∑–≤–∞–Ω–∏—è –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤ –Ω–∞ —Ä—É—Å—Å–∫–æ–º –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        criteria_names = {
            EvaluationCriteria.COMMUNICATION_SKILLS: "–ö–æ–º–º—É–Ω–∏–∫–∞—Ç–∏–≤–Ω—ã–µ –Ω–∞–≤—ã–∫–∏",
            EvaluationCriteria.MOTIVATION_LEARNING: "–ú–æ—Ç–∏–≤–∞—Ü–∏—è –∫ –æ–±—É—á–µ–Ω–∏—é",
            EvaluationCriteria.PROFESSIONAL_SKILLS: "–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ –Ω–∞–≤—ã–∫–∏",
            EvaluationCriteria.ANALYTICAL_THINKING: "–ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–æ–µ –º—ã—à–ª–µ–Ω–∏–µ",
            EvaluationCriteria.UNCONVENTIONAL_THINKING: "–ù–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –º—ã—à–ª–µ–Ω–∏–µ",
            EvaluationCriteria.TEAMWORK_ABILITY: "–ö–æ–º–∞–Ω–¥–Ω–∞—è —Ä–∞–±–æ—Ç–∞",
            EvaluationCriteria.STRESS_RESISTANCE: "–°—Ç—Ä–µ—Å—Å–æ—É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å",
            EvaluationCriteria.ADAPTABILITY: "–ê–¥–∞–ø—Ç–∏–≤–Ω–æ—Å—Ç—å",
            EvaluationCriteria.CREATIVITY_INNOVATION: "–ö—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –∏ –∏–Ω–Ω–æ–≤–∞—Ü–∏–∏",
            EvaluationCriteria.OVERALL_IMPRESSION: "–û–±—â–µ–µ –≤–ø–µ—á–∞—Ç–ª–µ–Ω–∏–µ"
        }

        total_criteria = len(EvaluationCriteria)
        for idx, criterion in enumerate(EvaluationCriteria, 1):
            criterion_name = criteria_names.get(criterion, criterion.value)
            logger.info(f"   üìå –ö—Ä–∏—Ç–µ—Ä–∏–π {idx}/{total_criteria}: {criterion_name}...")

            criterion_key = criterion.value
            score = scores.get(criterion_key, 5)
            examples = observations.get(criterion_key, [])

            # –°–æ–∑–¥–∞–Ω–∏–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ö–æ–ª–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
            explanation = self._generate_integrated_explanation(
                criterion, score, analysis, context
            )

            # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
            formatted_eval = self._format_evaluation_with_examples(
                score, explanation, examples
            )

            evaluation_score = EvaluationScore(
                criterion=criterion,
                score=score,
                verbal_score=self._extract_verbal_component(criterion, analysis, context),
                non_verbal_score=self._extract_nonverbal_component(criterion, analysis, context),
                explanation=explanation,
                key_observations=self._extract_key_observations(criterion, analysis, context),
                specific_examples=examples,
                formatted_evaluation=formatted_eval
            )

            detailed_scores[criterion] = evaluation_score
            logger.info(f"      ‚úì –û—Ü–µ–Ω–∫–∞: {score}/10")

        return detailed_scores
    
    def _classify_tempo(self, wpm: float) -> str:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ–º–ø–∞ —Ä–µ—á–∏"""
        if wpm < 120:
            return "–º–µ–¥–ª–µ–Ω–Ω—ã–π"
        elif wpm > 180:
            return "–±—ã—Å—Ç—Ä—ã–π"
        else:
            return "–Ω–æ—Ä–º–∞–ª—å–Ω—ã–π"
    
    def _get_dominant_emotion(self, emotions: Dict) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–æ–º–∏–Ω–∏—Ä—É—é—â–µ–π —ç–º–æ—Ü–∏–∏"""
        if not emotions:
            return "neutral"
        return max(emotions.items(), key=lambda x: x[1])[0]
    
    def _classify_gesture_intensity(self, frequency: int) -> str:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç–∏ –∂–µ—Å—Ç–æ–≤"""
        if frequency < 5:
            return "–Ω–∏–∑–∫–∞—è"
        elif frequency < 15:
            return "—É–º–µ—Ä–µ–Ω–Ω–∞—è"
        else:
            return "–≤—ã—Å–æ–∫–∞—è"
    
    def _assess_reliability(self, video_data: Dict, audio_data: Dict) -> str:
        """–û—Ü–µ–Ω–∫–∞ –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑–∞"""
        video_quality = video_data.get("video_quality", 5)
        audio_quality = audio_data.get("audio_quality", 5)
        avg_quality = (video_quality + audio_quality) / 2
        
        if avg_quality >= 8:
            return "–≤—ã—Å–æ–∫–∞—è"
        elif avg_quality >= 6:
            return "—Å—Ä–µ–¥–Ω—è—è"
        else:
            return "–Ω–∏–∑–∫–∞—è"
    
    def _assess_speech_emotion_sync(self, transcript_data: Dict, video_data: Dict) -> str:
        """–ê–Ω–∞–ª–∏–∑ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ —Ä–µ—á–∏ –∏ —ç–º–æ—Ü–∏–π"""
        # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è - –≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω—É–∂–µ–Ω –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∞–Ω–∞–ª–∏–∑
        emotions = video_data.get("emotion_analysis", {})
        positive_emotions = emotions.get("happy", 0) + emotions.get("surprise", 0)
        
        transcript = transcript_data.get("transcript", "").lower()
        positive_words = ["—Ö–æ—Ä–æ—à–æ", "–æ—Ç–ª–∏—á–Ω–æ", "–∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ", "–Ω—Ä–∞–≤–∏—Ç—Å—è", "—É–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω–æ"]
        positive_word_count = sum(1 for word in positive_words if word in transcript)
        
        if positive_emotions > 20 and positive_word_count > 0:
            return "—Ö–æ—Ä–æ—à–µ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ"
        elif positive_emotions < 10 and positive_word_count == 0:
            return "–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ"
        else:
            return "—Å–º–µ—à–∞–Ω–Ω–æ–µ"
    
    def _assess_gesture_speech_sync(self, transcript_data: Dict, video_data: Dict) -> str:
        """–ê–Ω–∞–ª–∏–∑ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏–∏ –∂–µ—Å—Ç–æ–≤ –∏ —Ä–µ—á–∏"""
        gesture_freq = video_data.get("gesture_frequency", 0)
        word_count = len(transcript_data.get("transcript", "").split())
        
        if word_count > 0:
            gesture_per_word = gesture_freq / word_count
            if 0.01 <= gesture_per_word <= 0.05:
                return "—Ö–æ—Ä–æ—à–∞—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—è"
            elif gesture_per_word > 0.05:
                return "–∏–∑–±—ã—Ç–æ—á–Ω–∞—è –∂–µ—Å—Ç–∏–∫—É–ª—è—Ü–∏—è"
            else:
                return "–Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞—è –∂–µ—Å—Ç–∏–∫—É–ª—è—Ü–∏—è"
        
        return "–Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–∞—è"
    
    def _generate_integrated_explanation(
        self, 
        criterion: EvaluationCriteria, 
        score: int, 
        analysis: Dict, 
        context: Dict
    ) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        
        criterion_info = CRITERIA_DESCRIPTIONS[criterion]
        base_explanation = f"–û—Ü–µ–Ω–∫–∞ {score}/10 –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—é '{criterion_info.name}'"
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª—å–Ω—ã—Ö –¥–µ—Ç–∞–ª–µ–π –∏–∑ –∫—Ä–æ—Å—Å-–º–æ–¥–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        cross_modal = analysis.get("cross_modal_insights", {})
        
        if criterion == EvaluationCriteria.COMMUNICATION_SKILLS:
            alignment = cross_modal.get("verbal_nonverbal_alignment", "")
            return f"{base_explanation}. {alignment}"
        
        elif criterion == EvaluationCriteria.STRESS_RESISTANCE:
            stress_indicators = cross_modal.get("stress_indicators", "")
            return f"{base_explanation}. {stress_indicators}"
        
        return base_explanation
    
    def _format_evaluation_with_examples(
        self, 
        score: int, 
        explanation: str, 
        examples: List[str]
    ) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ü–µ–Ω–∫–∏ —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏"""
        
        result = f"{score}/10 - {explanation}"
        
        if examples:
            examples_text = "; ".join(examples[:3])  # –ú–∞–∫—Å–∏–º—É–º 3 –ø—Ä–∏–º–µ—Ä–∞
            result += f" –ü—Ä–∏–º–µ—Ä—ã: {examples_text}"
        
        return result
    
    def _extract_verbal_component(
        self, 
        criterion: EvaluationCriteria, 
        analysis: Dict, 
        context: Dict
    ) -> int:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤–µ—Ä–±–∞–ª—å–Ω–æ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ –æ—Ü–µ–Ω–∫–∏"""
        # –ë–∞–∑–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è —Ä–µ—á–∏
        return min(5, max(1, analysis.get("holistic_scores", {}).get(criterion.value, 5) // 2 + 1))
    
    def _extract_nonverbal_component(
        self, 
        criterion: EvaluationCriteria, 
        analysis: Dict, 
        context: Dict
    ) -> int:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–µ–≤–µ—Ä–±–∞–ª—å–Ω–æ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ –æ—Ü–µ–Ω–∫–∏"""
        # –ë–∞–∑–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–µ–≤–µ—Ä–±–∞–ª—å–Ω–æ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è
        total_score = analysis.get("holistic_scores", {}).get(criterion.value, 5)
        verbal_score = self._extract_verbal_component(criterion, analysis, context)
        return min(5, max(1, total_score - verbal_score + 1))
    
    def _extract_key_observations(
        self, 
        criterion: EvaluationCriteria, 
        analysis: Dict, 
        context: Dict
    ) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö –Ω–∞–±–ª—é–¥–µ–Ω–∏–π"""
        observations = analysis.get("detailed_observations", {}).get(criterion.value, [])
        return observations[:3]  # –ú–∞–∫—Å–∏–º—É–º 3 –Ω–∞–±–ª—é–¥–µ–Ω–∏—è
    
    def _build_final_analysis(
        self,
        detailed_scores: Dict,
        context: Dict,
        comprehensive_analysis: Dict,
        candidate_info: Dict
    ) -> InterviewAnalysis:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        
        total_score = sum(score.score for score in detailed_scores.values())
        
        return InterviewAnalysis(
            candidate_id=candidate_info.get("id", "unknown"),
            candidate_name=candidate_info.get("name", "Unknown"),
            interview_duration=int(context["interview_content"]["duration_seconds"]),
            scores=detailed_scores,
            audio_quality=context["technical_quality"]["audio_quality"],
            video_quality=context["technical_quality"]["video_quality"],
            emotion_analysis=context["nonverbal_behavior"]["emotions_distribution"],
            eye_contact_percentage=context["nonverbal_behavior"]["eye_contact_percentage"],
            gesture_frequency=context["nonverbal_behavior"]["gesture_frequency"],
            posture_confidence=context["nonverbal_behavior"]["posture_confidence"],
            speech_pace=context["verbal_communication"]["tempo_classification"],
            vocabulary_richness=min(int(context["interview_content"]["linguistic_features"].get("vocabulary_richness", 0.5) * 10), 10),
            grammar_quality=context["interview_content"]["linguistic_features"].get("grammar_complexity", 5),
            answer_structure=self._assess_answer_structure(context["interview_content"]["transcript"]),
            total_score=total_score,
            weighted_score=self._calculate_weighted_score(detailed_scores),
            recommendation=comprehensive_analysis.get("recommendation", "–¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞"),
            detailed_feedback=comprehensive_analysis.get("comprehensive_feedback", "–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω"),
            analysis_timestamp=datetime.now().isoformat(),
            ai_model_version="integrated-v1.0"
        )
    
    def _calculate_weighted_score(self, scores: Dict) -> float:
        """–†–∞—Å—á–µ—Ç –≤–∑–≤–µ—à–µ–Ω–Ω–æ–π –æ—Ü–µ–Ω–∫–∏"""
        weights = {
            EvaluationCriteria.COMMUNICATION_SKILLS: 1.2,
            EvaluationCriteria.MOTIVATION_LEARNING: 1.1,
            EvaluationCriteria.PROFESSIONAL_SKILLS: 1.0,
            EvaluationCriteria.ANALYTICAL_THINKING: 1.0,
            EvaluationCriteria.UNCONVENTIONAL_THINKING: 0.9,
            EvaluationCriteria.TEAMWORK_ABILITY: 1.0,
            EvaluationCriteria.STRESS_RESISTANCE: 0.9,
            EvaluationCriteria.ADAPTABILITY: 0.9,
            EvaluationCriteria.CREATIVITY_INNOVATION: 0.8,
            EvaluationCriteria.OVERALL_IMPRESSION: 1.1
        }
        
        weighted_sum = sum(scores[criterion].score * weights[criterion] for criterion in scores)
        total_weight = sum(weights.values())
        
        return weighted_sum / total_weight
    
    def _assess_answer_structure(self, transcript: str) -> int:
        """–û—Ü–µ–Ω–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ –æ—Ç–≤–µ—Ç–æ–≤"""
        structure_markers = [
            "–≤–æ-–ø–µ—Ä–≤—ã—Ö", "–≤–æ-–≤—Ç–æ—Ä—ã—Ö", "–≤-—Ç—Ä–µ—Ç—å–∏—Ö",
            "—Å –æ–¥–Ω–æ–π —Å—Ç–æ—Ä–æ–Ω—ã", "—Å –¥—Ä—É–≥–æ–π —Å—Ç–æ—Ä–æ–Ω—ã",
            "–Ω–∞–ø—Ä–∏–º–µ—Ä", "–≤ —á–∞—Å—Ç–Ω–æ—Å—Ç–∏", "—Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º",
            "–≤ –∑–∞–∫–ª—é—á–µ–Ω–∏–µ", "–ø–æ–¥–≤–æ–¥—è –∏—Ç–æ–≥"
        ]
        
        marker_count = sum(1 for marker in structure_markers if marker in transcript.lower())
        return min(marker_count + 3, 10)
    
    def _get_fallback_analysis(self) -> Dict:
        """–ó–∞–ø–∞—Å–Ω–æ–π –∞–Ω–∞–ª–∏–∑ –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏"""
        return {
            "holistic_scores": {criterion.value: 5 for criterion in EvaluationCriteria},
            "cross_modal_insights": {
                "verbal_nonverbal_alignment": "–ê–Ω–∞–ª–∏–∑ –Ω–µ —É–¥–∞–ª—Å—è",
                "emotional_consistency": "–ù–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π",
                "confidence_indicators": "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã",
                "stress_indicators": "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã"
            },
            "detailed_observations": {criterion.value: ["–ê–Ω–∞–ª–∏–∑ –Ω–µ —É–¥–∞–ª—Å—è"] for criterion in EvaluationCriteria},
            "comprehensive_feedback": "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —Å–±–æ–π –≤ –∞–Ω–∞–ª–∏–∑–µ",
            "recommendation": "–¢—Ä–µ–±—É–µ—Ç—Å—è –ø–æ–≤—Ç–æ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑"
        }
